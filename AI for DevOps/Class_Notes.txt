AI for DevOps :::

Introduction to AI for DevOps :

DevOps/AWS/Azure :::

-> DevOps!

-> -> Process to automate CICD.

   -> Open-Source DevOps Tools 
		-> git,jenkins,docker,kubernetes		
		-> Ansible,Terraform
		
   -> AWS/Azure/GCP Cloud Services ==> Essentials
   
   -> AI for DevOps - Multi-Cloud Platform	--> Add Value to Profile.
   
   -> Use cases,Real Time Scenarios 
   -> FAQs 
   -> Real Time Scenarios based FAQs


AI for DevOps :::

DevOps/AI :

Docker,Kubernetes,Prometheus,Grafana

No 

No Proper response from AI!

Drawback!

Opportunity!

	- AI Model 	-> Backend Data 
	
	- AI Prompts -> Prompt Engineers!
	
	- AI Models  -> 
	
	- Core of AI Solutions -> 
	
	- Roles & Responsibilities ->
	
	- Continuous Learning :	
	
	- DevOps/Cloud Resources => 
	
	- Developers/Testing/Monitoring ==> AI 
	
	-> DevOps Journey!
	
		--> DevOps,DevSecOps,MLOps,AIOps,GitOps,SRE,
			-----------------------------------------> AI Driven Solutions
			
			-> Peak Time! AI 
			
	-> Ask to AI ....	
	
Introduction to AI for DevOps ::::

	- Gen-AI

	- AI for DevOps :::
	
	- DevOps/Cloud AWS :::
	
	
	- Data ?
	
	-> Gen-AI ????
	
	-> Face Detection Algorithm! 
	
	-> cicd ->
	
		Java/.Net/Python/




#########################
Day 3 : 14th Oct. 2025
#########################


	Create Application Source Code
	
	
	Automate Testing!
	
	
	Containerized Application Service
	
	Jenkinsfile!
	
	
	Application Deployment :
	
		- Docker 
			
			Dockerfile ?
		
		- Kubernetes 
		
		
	Production Deployments :
	
		- Ensure High Availability 
		
	Kubernetes Architecture ::::
	
		Kubernetes_Master 
			Kubernetes_WorkerNodes!
	
	
	Kubernetes Architecture Components ???
	
		- ETCD 						- KM
		
		- APIServer 				- KM
		
		- Scheduler 				- KM 
		
		- Kubelet 					- KM,WN
		
		- CRI - Container-D			- KM,WN
		
		- Controller Manager		- KM
		
		- KubeProxy 				- KM,WN
		
		
		
	APIServer :
	
	PODs
	
	5 replicas of pod
	
	
	Controller Manager :
	
		Deployment Controller Object
		
		
		Auto-Scaling ::::
		
			Kubectl scale command ?
		
		kubectl scale deployment nginx-deploy --replicas=10
		
		
		
		Microservice ==> 20 replicas of pods - 100 users
		
						 40+					200 users requests
						 
						 
						 CPU Utilization/Memory/Network Traffic			==> AI 
						 
						 Threshold Limit ==> 80%
						 
						 min & max limit of pods 
						 
						 
		kubectl autoscale deployment nginx-deploy --min=2 --max=10 --cpu=70%
		
		
		
		Monitoring of Infra-Structure :::
		
			Prometheus & Grafana.			
				- CPU 
				- Memory
				- Network
			
		Can you Monitor Kubernetes Cluster ????
		
		Steps to Monitor Kubernetes Cluster!
		
		
		apt 
		
		yum 
		
		
		apt install nginx	
		
		
		Helm Package Manager!				***********
		
			Helm is Package Manager for Kubernetes
			
			Using Helm we can install/Manage any Package Deployment in Kubernetes.
			
			
			Install Helm 
			
			& Using Helm, Install Prometheus/Grafana
			

Next :
			
	K8sGPT --> Proactively Monitor & Manage the Kubernetes Clusters
			
			
Use AI for below :	

	1. Developers Perspective
	
	2. DevOps - Application CICD Perspective
	
	3. Application/Infra-Structure Monitoring Perspective
	
	4. Infra-Structure Provisioning/Configuration Perspective	

				- Using Terraform



		
		
				
#########################
Day 4 : 14th Oct. 2025
#########################		

	
	Docker & Kubernetes 		===> Based on Production Level Implementation using Kubeadm!

	Kubernetes :::
	
		-> Minikube 		=> Single Node Kubernetes 	==> This is not meant for Production Level. 
		
		-> Kubeadm			=> Multi-Node Kubernetes Architecture ==> This is meant for Production Level. 
		
	
	Kubernetes ::::
	
		-> Kubernetes is an Open-Source Container Orchestration Tool.
		-> Kubernetes is used to Deploy Containerized Micro-Service based Applications to ensure high availability.
		-> Kubernetes create the replicas of pods(Is a smallest/Atomic Unit of Task) using Replicasets.
		-> Kubernetes supports Auto-Scaling & Load Balancing 
		-> Kubernetes Support Self-Healing		
	
	
	Managed Services from the Service Providers :::
	
		AWS 	:	ECS,ECR,EKS 
		Azure 	:	ACS,ACR,AKS
		GCP		:	GCE,GCR,GKE
		
		
	
	Containerization :
	
		-> Is a process of packaging the Application along with its dependencies.
		-> Docker Container Engine is used to Containerize the Applications
		
	
	Any Web/Mobile Application		==> are developed using Micro-Service Service Based Application Architecture.
	
	Netflix/Facebook/Amazon/
	
	
	on DevOps Perspective :
	
		-> Monolith Application 
				- Tightly coupled Applications - 
		
		-> Micro-Service based Application 
				- Loosely Coupled Application Architecture - 
	
	
		Web App :
		
		www.amazon.com		==> Web Application
		
		Functions ::::
		
		
		Sign-Up 		==> Micro-Service1	-> 3-tier ==> Developer1 -> Code Change,Test,Release the changes to prod 
		Sign-In 		==> Micro-Service2	-> 3-tier ==> 
		Search 			==> Micro-Service3
		Add to Cart 
		Place Order 
		Make Payment
		Confirm Order 
		Track
		
		
	Docker,Kubernetes,Terraform,Jenkins ==> 
	
	git,Ansible,Monitoring Tools ==>
	
	
	Working with Kubernetes :::
	
		- Setup the Kubernetes Architecture using kubeadm.
		
		- Kubernetes_Master
			- Kubernetes_WorkerNode1
			- Kubernetes_WorkerNode2
			- Kubernetes_WorkerNode3
			
			
	Kubernetes Concepts & Terminologies :
	
		- Pod 
			-> Is a smallest/Atomic Unit of Task/schedule
			-> Pod Deployment 
				-> Single Container Pod 
				
				-> Multi-Container Pod 
			
		- Kubernetes Cluster 
			-> It is a collection of Kubernetes WorkerNodes 
				- The Application Pods are actually deployed in the WorkerNodes.
			
			-> Minimum 3 WorkerNodes

			- Kubernetes_Master
				- Kubernetes_WorkerNode1
				- Kubernetes_WorkerNode2
				- Kubernetes_WorkerNode3

			
			- Kubernetes_Master(VM)			
				Kubernetes_Cluster1 									AWS - Mumbai Region
					- Kubernetes_WorkerNode1(VM)
					- Kubernetes_WorkerNode2(VM)
					- Kubernetes_WorkerNode3(VM)			
				Kubernetes_Cluster2 									AWS - Tokyo Region
					- Kubernetes_WorkerNode1(VM)
					- Kubernetes_WorkerNode2(VM)
					- Kubernetes_WorkerNode3(VM)			
				Kubernetes_Cluster3 									AWS - Singapore Region
					- Kubernetes_WorkerNode1(VM)
					- Kubernetes_WorkerNode2(VM)
					- Kubernetes_WorkerNode3(VM)		
		
			- Kubernetes_Master(VM)											On-Prem	
				- Kubernetes_Master1(VM)									AWS		
					Kubernetes_Cluster1 									AWS - Mumbai Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)			
					Kubernetes_Cluster2 									AWS - Tokyo Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)			
					Kubernetes_Cluster3 									AWS - Singapore Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)		
			
				- Kubernetes_Master2(VM)									Azure 			
					Kubernetes_Cluster1 									Azure - Mumbai Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)			
					Kubernetes_Cluster2 									Azure - Tokyo Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)			
					Kubernetes_Cluster3 									Azure - Singapore Region
						- Kubernetes_WorkerNode1(VM)
						- Kubernetes_WorkerNode2(VM)
						- Kubernetes_WorkerNode3(VM)		
		
		
		
		- Kubectl 

			- Is an Command Line Utility to interact with Kubernetes Master 
		
		- Kubelet 
			- Is an Agent to deploy the pods 
		
		- Kubeadm 
			- Is an Command Line Utility used to configure the Kubernetes Architecture Components
		
		Controller Object :::
			ReplicaSet 
			Deployment 


		ReplicaSet :::
		
			--> Replicaset is used to execute the specific no. of pods in the cluster.
			--> Replicaset uses the Set Based Operator
			--> Used to replicate the pods and able to scale up/down
			--> The Replicasets will be automatically created, while creating Deployment Controller Object.
		
		Deployment Controller Object :::
		
			--> It is used to deploy the pods and ensure high availability of pods by creating pod replicas 
			--> 1. Create Muliple instance/replicas/copies of pods 
				2. Used to Scale-Up / Scale-Down the Pods 
				3. Used to Upgrade the application pods 
				4. Used to Down-grade/roll-back the application pods
			--> The upgrade/down-grade of application pods can be done without any downtime. 
			--> To achieve zero-downtime during upgrade/down-grade, By Default, it used Rolling-Update Deployment Strategy.
				
				CICD --> Continuous Integration/Continuous Deployment 
				
		myweapp_v1.0_Snapshot.war						myweapp_Img:v1.0	
		
		myweapp_v1.1_Snapshot.war						myweapp_Img:v1.1			# Minor Release 
		
		myweapp_v2.0_Snapshot.war						myweapp_Img:v2.0			# Major Release 

		Deployed using 3 replicas of pods 		-- using  Rolling-Update Deployment Strategy.
		
		
		Pod1	==> myweapp_Img:v1.0		=============>			myweapp_Img:v1.1
		
		Pod2 	==>	myweapp_Img:v1.0		=============>			myweapp_Img:v1.1
		
		Pod3 	==> myweapp_Img:v1.0		=============>			myweapp_Img:v1.1
			
		
		- Services 
			
			- NodePort				==> 	30000 - 32767		--> Open this range of ports 
				---> 	To expose the pods to internet we use NodePort Service
				
			- ClusterIP
				--->	To Maintain the Pods Network Within the Cluster.
				
			- LoadBalancers
			
			
			
			3-Tier Application Architecture :
			
			
				Front-End 			- User Interface 	- Pod1.1,1.2,1.3
				
				Application Layer 	- Business Logic	- Pod2.1,2.2,2.3 
				
				Back-End Layer 		- DataBase			- Pod3.1,3.2,3.3
			
			
		- Volumes 
		
			- Hostpath 
			- Persistant Volume 
			- Persistant Volume Claim
		


Next :::	

		Demo on Kubernetes using KubeAdm.



#########################
Day 5 : 17th Oct. 2025
#########################					

	Demo on Kubernetes using KubeAdm.
	
		- Kubernetes_Master
			- Kubernetes_WorkerNode1
			- Kubernetes_WorkerNode2			


	- Kubernetes_Master
		- Kubernetes_WorkerNode1
		- Kubernetes_WorkerNode2			
			
			
	Installation of Kubernetes using Kubeadm :::	
	
		1. Launch 3 VMs on AWS Cloud (Ubuntu v22.04) --> (1 Master Node, 2 WorkerNodes)
		
		In all the Nodes(i.e., Master Node and WorkerNodes):
		
			2. Allow all traffic for all the nodes - just for this demo
			3. Change the HostName of all the Nodes
			4. Disable swap configuration in all the nodes
			5. Install Docker in all the nodes										# Optional
			6. Install CRI - 'Container-D' in all the nodes
			7. Install Kubeadm,kubelet,kubectl 
			8. Enable Kubelet	
		   
		Only on Master Node:
		
			9. Execute Kubeadm Init Command 		# To initialize Kubernetes Master Node
			10. Enable user Access to Kubernetes
			11. Install flannel Network plugins for kubeproxy

		Only on WorkerNodes:		
		
			12. Execute Kubeadm Join Command 		# To attach the Worknodes with Kubernetes Master Node.			
			
			

		Controller Object :::
			ReplicaSet 
			Deployment 


		ReplicaSet :::
		
			--> Replicaset is used to execute the specific no. of pods in the cluster.
			--> Replicaset uses the Set Based Operator
			--> Used to replicate the pods and able to scale up/down
			--> The Replicasets will be automatically created, while creating Deployment Controller Object.
		
		Deployment Controller Object :::
		
			--> It is used to deploy the pods and ensure high availability of pods by creating pod replicas 
			--> 1. Create Muliple instance/replicas/copies of pods 
				2. Used to Scale-Up / Scale-Down the Pods 
				3. Used to Upgrade the application pods 
				4. Used to Down-grade/roll-back the application pods
			--> The upgrade/down-grade of application pods can be done without any downtime. 
			--> To achieve zero-downtime during upgrade/down-grade, By Default, it used Rolling-Update Deployment Strategy.



		--> Deployment Object 
		--> ReplicaSet
		--> Pod Instances 
	


#########################
Day 6 : 21st Oct. 2025
#########################	


	AIOps & MLOps ::: 
	
	
		- DevOps Perspective :
		
	AI -- 
	
	ML --
		
		
	
	
	K8sGPT to Monitor Kubernetes - Based On AIOps 
	
	
	IAC - To Provision the Resources - Using AI Tools with Terraform
		
		
		


#########################
Day 7 : 23rd Oct. 2025
#########################

	Prometheus/Grafana -> Monitoring

	K8sGPT -> Used to Analyze Kubernetes Cluster.

	Kubernetes Dashboard -> Manage the Kubernetes Objects using GUI Mode.	

	Kubectl --> 	
	
	EKS/AKS/GKE --> GUI Based solutions
	
	
	Helm ==> Is Kubernetes Package Manager 



User Authentication :::

	- 	Password Based Authentication
	-	Key Based Authentication
	-	Token Based Authentication
	- 	Passwordless Authentication


Kubernetes - uses Token Based Authentication.

Create Service Account :

	
	- Authentication	-> Who can Access ?		Service Account Id
	
	- Authorization 	-> What Level of Access?
	
		--> RBAC : Role Based Access Control 
		
				Developer 
				Admin 
				Manager 
				Guest
				
		--> Kubernetes Cluster Level Access 
		
				- Service Account is Create at the Cluster Level Access.
				
					clusterrolebinding
		
		--> Kubernetes Namespace Level Access 
					
					rolebinding

		- Kubernetes Cluster 
			-> It is a collection of Kubernetes WorkerNodes 
				- The Application Pods are actually deployed in the WorkerNodes.
				
	Non-Prod : 										Prod :  24/7
		                                            
	Kubernetes_Master                               Kubernetes_Master
		Kubernetes_WorkerNode1                      	Kubernetes_WorkerNode1
		Kubernetes_WorkerNode2                      	Kubernetes_WorkerNode2
		Kubernetes_WorkerNode3												
        Kubernetes_WorkerNode4
		Kubernetes_WorkerNode5
        Kubernetes_WorkerNode6
		Kubernetes_WorkerNode7


	Namespace : Is a logical partitioning of Kubernetes Cluster
				Namespace can be created based the Environments/Teams
				
	
				
	
	
	K8sGPT -> Used to Analyze Kubernetes Cluster :::::::
		
		https://k8sgpt.ai/docs
		
		
		https://openai.com/
		
		
		
Kubernetes Services :
	NodePort 
	ClusterIP
	LoadBalancer
	
	Ingress Controller Object:::
		- To reduce the LoadBalancer
		
		- Ingress Rulesets:::
		
			-> Simple Routing 			# Static Web Page like Blogsite/Web Articles
			
			-> Host Based Routing
			
			-> Path Based Routing 
			
			-> Query Based Routing 
		
		
	www.google.com ---> URL -> LoadBalancer URL (Application Level)
	
		-> gmail 
		
			www.google.gmail.com 			==> Host Based Routing	
		
		-> drive 
		
			www.google.drive.com			==> Host Based Routing	
		
		-> Maps 
		
			www.google.maps.com				==> Host Based Routing	
			
		-> translate 
		
		
	
	www.google.gmail.com
	
		inbox 			->	www.google.gmail.com/inbox					=> Path Based Routing
		sent			->	www.google.gmail.com/sent					=> Path Based Routing
		trash
		spam
	
	
	www.google.gmail.com/inbox	
	
		Search Mail : @xxx.com
	
					www.google.gmail.com/inbox?@xxx.com					=> Query Based Routing 
					www.google.gmail.com/sent?@xxx.com					=> Query Based Routing 
	

	
#########################
Day 8 : 23rd Oct. 2025
#########################	

	
	Infra-Structure Provisioning/Configuration Perspective	
				- Using Terraform
				
	-->
	
		Infra-Structure Provisioning :
		
		IAC - Infra-Structure As Code 
		
		AWS Cloud --> Cloudformation Service 
		
		Azure --> Azure Resource Manager - ARM 
		
		
		Multi-Cloud / Hybrid Environments :::::
		
			IAC --> Terraform
			
					Terraform Registries ---> 
					
		Terraform :::
		
			==> AWS Cloud Platform :::
			
			==> HCL Scripts 
			
		1. Virtual Design the Architecture
		
		2. Using Terraform Registry - Create the Terraform IAC.
			https://registry.terraform.io/browse/providers
		
		3. VS Code to Write the Terraform Scripts
		
		
	Terraform Workflow :
	
		1. Identify the Scope of Infra-Structure - AWS/Azure/GCP
		
		2. Write Terraform Scripts 
		
		3. Perform Terraform Init --> Initialize Terraform Provider 
		
		4. Perform Terraform Plan --> Preview/Validate the Resource Configuration
		
		5. Perform Terraform Apply --> Implement the Actual Changes in the Real Infra-Structure
		
		
	AI - Copilot :
	
		- To Create Terraform Project.
		
		- GenAI --> Generate Terraform Scripts & Architecture Diagram 
		
Next: 
		
Q/A ::::




		
		
#######################
Day 9 : 29th Oct. 2025
#######################
		
	Project Discussion ::::
	
	
	How to Implement DevOps Solutions ::::
	

- Prepare Jenkins CI-CD Pipeline Projects using Docker & Kubernetes ::
	
	
	Pipeline Stages ::: 
	
	Create Jenkins CI Pipeline :	Using Docker & Kubernetes
	
	
		1. SCM-Checkout
		
		2. Application Build 			*.war 
		
		3. Application Image Build 
		
		4. Login to DockerHub 
		
		5. Push to DockerHub 
		
		6. Deploy to Kubernetes
			
	
	
	DevOps Assessment :
	
		- Interact with all the teams and collect the detailed requirements 
		
		
		
	Phase 1 :
		-> 	Infra-Structure Provisioning and Configurations 
				- Using Terraform and Ansible 
				- Using AWS Console 		
			
			If the Servers are already available just reuse. Else, create using AWS Console / Terraform & configure it using Ansible.
	
	
	Phase 2 :
		-> 	Automation of Application Builds & Deployments  
				- Using Jenkins CICD Pipelines
		
		
	Phase 3 :
		-> 	Monitoring of Infra-Structure
				- Using Prometheus & Grafana
				
				
	What are the Servers(VM) needed ?
	
	What are the tools to be configured in each server ?
	
	What are the stages of CICD Pipeline ?
	

	- Implementation Procedures / Steps ::::
	
		1. List of Servers :: 
		
			Infra-Structure Management Team's Perspectives ::::
			
				- Create using AWS Console 
				
				- Create using Terraform / Ansible 
				
			
			On DevOps Perspectives :	# Create CICD Pipeline ::::			

				- Jenkins_Master 						VM1 				# https://www.jenkins.io/doc/book/installing/
					- Jenkins_SlaveNode(Build_Server)	VM2 
				
				- Kubernetes_Master						VM3
					- Kubernetes_WorkerNode1			VM4 
					- Kubernetes_WorkerNode2			VM5 

				
			Production Support/Monitor Teams' Perspective ::::
		
				- Monitor the Kubernetes Cluster/Jenkins_Slave_Nodes using Prometheus & Grafana :				
				
					- Dedicated Monitoring Server! 		VM6						# Monitor Jenkins_Master & Jenkins_Slave_Nodes
				
					- Dedicated Monitoring Services(Prometheus & Grafana)		# To Monitor Kubernetes Cluster & Pods
	
	
	
			Servers & it's purpose :::
			
			
				- Jenkins_Master 						VM1 	# To create CICD Pipeline Jobs and schedule it to run in Slave Nodes	
				
					- Jenkins_SlaveNode(Build_Server)	VM2 	# Checkout the Source_Code for GIT
																# Compile the Source Code
																# Create Artifacts
																# Perform Unit Testing 
																# Create Application Image
																# Publish the Application Image to Container Registry
																
				
				- Kubernetes_Master						VM3		# Schedule the Pods Deployment 
																# Execute Kubernetes Monitoring Services using Prometheus & Grafana
													
					- Kubernetes_WorkerNode1			VM4 	# Execute the Pods
					- Kubernetes_WorkerNode2			VM5 	# Execute the Pods

				
				
				- Monitoring Server 					VM6		# To Monitor Jenkins_Master & Jenkins_Slave_Nodes
																# Create Monitoring Dashboards
				
				
		2. List of Tools :: 				
				
				- Jenkins_Master 						VM1 	# git,jdk,jenkins
					- Jenkins_SlaveNode(Build_Server)	VM2 	# git,jdk,maven,docker
					
				- Kubernetes_Master						VM3		# All Kubernetes Components	
					- Kubernetes_WorkerNode1			VM4 
					- Kubernetes_WorkerNode2			VM5 


			Manage the Credentials to access DockerHub,Jenkins_SlaveNodes,Kubernetes,Github(private repo)
			
					goto jenkins dashboard 
						-- Manage Jenkins 
							-- Credential 
								-- using dockerhub username and access token
								
			
			Integration of Kubernetes Master Node with Jenkins Master Node.
			
				- Using Publish over ssh plugins, integrate Kubernetes_Master Node to Jenkins Master Node
				
				- And Execute kubectl create command using Publish over ssh plugins
				
				--> 1. Create a devopsadmin - User in Kubernetes_Master
				
				--> 2. Create SSH Keys to devopsadmin - User
				
				--> 3. Ensure that devopsadmin - User have access to execute kubectl commands
				
				--> 4. Use, the Kubernetes - Master Node's - Private IP Address,User_Name and Credential to config in Jenkins - Publish Over SSH
				
				--> 5. Create a Pipeline Deployment Stage using Publish Over SSH Plugins step
						- To copy the kubernetes manifest file - *.yaml file from jenkins_Slave Node to Kubernetes Master Node.
						- To execute a command : kubectl apply -f kubernetesdeploy.yaml				
			
			
		
		
		
		3. CICD Pipeline Stages :::
		
			- SCM Checkout 
			
			- Application Build 
			
			- Application Image Build
			
			- Login to DockerHub 

			- Publish Application Image to DockerHub Container Registry
			
			- Deploy the Application Images to Target Environments(QA/PROD) using Kubernetes			
		
		
		



#######################
Day 9 : 29th Oct. 2025
#######################


	- Configured Jenkins Master Node 
	
	- Installed Publish over SSH Plugins 
		

	Project Demo:
	
		CICD Pipeline :::
		
		
		Configure Jenkins Slave Node :
		
				- Jenkins_Master 						VM1 	# git,jdk,jenkins
					- Jenkins_SlaveNode(Build_Server)	VM2 	# git,jdk,maven,docker		
					
					
				- Create SSH Key in Slave Node to enable SSH Connection to Jenkins Master Node 
				
					- SSH COnnection :
					
						- Host Name   ==> Private_IP
						
						- User Name 
						
						- User Credentials (SSH-Key Pair)
			

		docker login -u lo,n
		
		kjk
		
		
						
pipeline {
    agent { label 'slave1' }

	environment {	
		DOCKERHUB_CREDENTIALS=credentials('dockerloginid1')
	}

    stages {
        stage('SCM_Checkout') {
            steps {
                echo 'Perform SCM Checkout'
				git 'https://github.com/PL-DevOps-GenAI-0625/BankingWebApp.git'			
            }
        }
        stage('Application Build') {
            steps {
                echo 'Perform Application Build'
				sh 'mvn clean package'
            }
        }
        stage('Application Image Build') {
            steps {
                echo 'Perform Application Image Build'
				sh "docker build -t loksaieta/bankingwebapp:${BUILD_NUMBER} ."
				sh "docker tag loksaieta/bankingwebapp:${BUILD_NUMBER} loksaieta/bankingwebapp:latest"
            }
        }
        stage('Login to DockerHub') {
            steps {
                echo 'Login to DockerHub'
				sh 'echo $DOCKERHUB_CREDENTIALS_PSW | docker login -u $DOCKERHUB_CREDENTIALS_USR --password-stdin'				
            }
        }
        stage('Push to DockerHub') {
            steps {
                echo 'Push Image to DockerHub'
				sh "docker push loksaieta/bankingwebapp:${BUILD_NUMBER}"
				sh "docker push loksaieta/bankingwebapp:latest"
				sh "docker rmi loksaieta/bankingwebapp:${BUILD_NUMBER}"
				sh "docker rmi loksaieta/bankingwebapp:latest"
            }
        }
        stage('Deploy to Kubernetes') {
            steps {
                script
				{
				sshPublisher(publishers: [sshPublisherDesc(configName: 'KMaster', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'kubectl apply -f bankingdeploy.yaml', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '.', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.yaml')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])
				}				
            }
        }
    }
}						
		


		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
